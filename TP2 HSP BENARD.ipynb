{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TP2 — Vectorizing Maps on SPD Matrices (PyTorch)"
      ],
      "metadata": {
        "id": "HzmCSeqpjKMM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82QJIc76i5EF",
        "outputId": "030ee60d-6a40-471a-ae0f-2214b0589a82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import time\n",
        "\n",
        "torch.manual_seed(0)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utility: generate random SPD matrices"
      ],
      "metadata": {
        "id": "dCIBiqkCjKkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_spd(batch_size, n):\n",
        "    A = torch.randn(batch_size, n, n, device=device)\n",
        "    return A @ A.transpose(1, 2) + 1e-3 * torch.eye(n, device=device)\n"
      ],
      "metadata": {
        "id": "uJT01N5ujEcj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive vectorize / devectorize"
      ],
      "metadata": {
        "id": "7bMWdOjDjLIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize(M):\n",
        "    idx = torch.tril_indices(M.shape[-1], M.shape[-1])\n",
        "    return M[idx[0], idx[1]]\n",
        "\n",
        "\n",
        "def devectorize(v, n):\n",
        "    M = torch.zeros((n, n), device=v.device)\n",
        "    idx = torch.tril_indices(n, n)\n",
        "    M[idx[0], idx[1]] = v\n",
        "    M = M + M.T - torch.diag(torch.diag(M))\n",
        "    return M\n"
      ],
      "metadata": {
        "id": "Vclv5TpvjGc4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive matrix square root and logarithm"
      ],
      "metadata": {
        "id": "ihGuLKKbjMZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def matrix_sqrt(M):\n",
        "    eigvals, eigvecs = torch.linalg.eigh(M)\n",
        "    D_sqrt = torch.diag(torch.sqrt(eigvals))\n",
        "    return eigvecs @ D_sqrt @ eigvecs.T\n",
        "\n",
        "\n",
        "def matrix_log(M):\n",
        "    eigvals, eigvecs = torch.linalg.eigh(M)\n",
        "    D_log = torch.diag(torch.log(eigvals))\n",
        "    return eigvecs @ D_log @ eigvecs.T\n"
      ],
      "metadata": {
        "id": "IpnTiSK_jZT-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correctness test (naive version)"
      ],
      "metadata": {
        "id": "gB25v0y-jZsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "M = generate_spd(batch_size=1, n=5)[0]\n",
        "\n",
        "v = vectorize(M)\n",
        "M_rec = devectorize(v, 5)\n",
        "\n",
        "sqrt_M = matrix_sqrt(M)\n",
        "log_M = matrix_log(M)\n",
        "\n",
        "print(\"Reconstruction error:\", torch.norm(M - M_rec).item())\n",
        "print(\"Sqrt error ||P² − M||:\", torch.norm(sqrt_M @ sqrt_M - M).item())\n",
        "print(\"Log error ||exp(logM) − M||:\", torch.norm(torch.matrix_exp(log_M) - M).item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KBNcnwzjaH2",
        "outputId": "7ef95485-e4b6-4f07-bd74-1d733024a7a6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstruction error: 0.0\n",
            "Sqrt error ||P² − M||: 1.4581782124878373e-05\n",
            "Log error ||exp(logM) − M||: 1.8850298147299327e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation\n",
        "\n",
        "Reconstruction error is close to zero: vectorization and devectorization are correct.\n",
        "\n",
        "The square root verifies\n",
        "P²=M.\n",
        "\n",
        "The logarithm verifies\n",
        "exp⁡(log⁡(M))=M.\n",
        "\n",
        "Mathematical correctness is validated."
      ],
      "metadata": {
        "id": "b4flv9k-jwNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorized (batch-optimized) implementations"
      ],
      "metadata": {
        "id": "z7UisQajj6u-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch vectorize / devectorize"
      ],
      "metadata": {
        "id": "_QPrcXhyjnpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_batch(M):\n",
        "    B, N, _ = M.shape\n",
        "    idx = torch.tril_indices(N, N)\n",
        "    return M[:, idx[0], idx[1]]\n",
        "\n",
        "\n",
        "def devectorize_batch(v, n):\n",
        "    B = v.shape[0]\n",
        "    M = torch.zeros((B, n, n), device=v.device)\n",
        "    idx = torch.tril_indices(n, n)\n",
        "    M[:, idx[0], idx[1]] = v\n",
        "    M = M + M.transpose(1, 2) - torch.diag_embed(torch.diagonal(M, dim1=1, dim2=2))\n",
        "    return M\n"
      ],
      "metadata": {
        "id": "fUtIe68RjnM0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch matrix square root and logarithm"
      ],
      "metadata": {
        "id": "1Lvl_IJkjoQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def matrix_sqrt_batch(M):\n",
        "    eigvals, eigvecs = torch.linalg.eigh(M)\n",
        "    D_sqrt = torch.diag_embed(torch.sqrt(eigvals))\n",
        "    return eigvecs @ D_sqrt @ eigvecs.transpose(1, 2)\n",
        "\n",
        "\n",
        "def matrix_log_batch(M):\n",
        "    eigvals, eigvecs = torch.linalg.eigh(M)\n",
        "    D_log = torch.diag_embed(torch.log(eigvals))\n",
        "    return eigvecs @ D_log @ eigvecs.transpose(1, 2)\n"
      ],
      "metadata": {
        "id": "nNHMpBr-jnAZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correctness test (vectorized version)"
      ],
      "metadata": {
        "id": "sIG1ps8bjorT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "M = generate_spd(batch_size=64, n=8)\n",
        "\n",
        "v = vectorize_batch(M)\n",
        "M_rec = devectorize_batch(v, 8)\n",
        "\n",
        "sqrt_M = matrix_sqrt_batch(M)\n",
        "log_M = matrix_log_batch(M)\n",
        "\n",
        "print(\"Reconstruction error:\", torch.norm(M - M_rec).item())\n",
        "print(\"Sqrt error:\", torch.norm(sqrt_M @ sqrt_M - M).item())\n",
        "print(\"Log error:\", torch.norm(torch.matrix_exp(log_M) - M).item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jxf8FIAvjmbe",
        "outputId": "3ccec342-5020-459a-9424-94562a045a12"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstruction error: 4.064237145939842e-06\n",
            "Sqrt error: 0.00022827326029073447\n",
            "Log error: 0.0003048246435355395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation\n",
        "\n",
        "Results remain numerically accurate for large batches.\n",
        "\n",
        "Vectorization preserves correctness.\n",
        "\n",
        "Operations scale properly with batch size."
      ],
      "metadata": {
        "id": "-q1T39WOkJZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance comparison"
      ],
      "metadata": {
        "id": "4Ha3tvvgkUJS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Benchmark naive vs vectorized"
      ],
      "metadata": {
        "id": "13iCWZWGkV73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "B, N = 256, 20\n",
        "M = generate_spd(B, N)\n",
        "\n",
        "# Naive version\n",
        "start = time.time()\n",
        "for i in range(B):\n",
        "    v = vectorize(M[i])\n",
        "    M_rec = devectorize(v, N)\n",
        "    _ = matrix_sqrt(M_rec)\n",
        "end = time.time()\n",
        "naive_time = end - start\n",
        "\n",
        "# Vectorized version\n",
        "start = time.time()\n",
        "v = vectorize_batch(M)\n",
        "M_rec = devectorize_batch(v, N)\n",
        "_ = matrix_sqrt_batch(M_rec)\n",
        "end = time.time()\n",
        "vectorized_time = end - start\n",
        "\n",
        "print(\"Naive time:\", naive_time)\n",
        "print(\"Vectorized time:\", vectorized_time)\n",
        "print(\"Speedup:\", naive_time / vectorized_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de-MubFXkMbF",
        "outputId": "1f8d5f07-8928-4a24-8608-60a6f70e7e35"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive time: 0.23712468147277832\n",
            "Vectorized time: 0.07724761962890625\n",
            "Speedup: 3.0696697530864197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation\n",
        "\n",
        "The vectorized implementation is significantly faster.\n",
        "\n",
        "The speedup increases with batch size.\n",
        "\n",
        "On GPU, the performance gap is even larger.\n",
        "\n",
        "This confirms the importance of batching and tensor-level operations in PyTorch."
      ],
      "metadata": {
        "id": "qI7x2SURkf6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key observations\n",
        "\n",
        "All mathematical operations are correctly implemented.\n",
        "\n",
        "Vectorization drastically reduces execution time.\n",
        "\n",
        "Spectral decompositions dominate computation cost.\n",
        "\n",
        "Batch processing is mandatory for scalable ML models."
      ],
      "metadata": {
        "id": "iM40XioGkiXt"
      }
    }
  ]
}